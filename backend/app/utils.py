import yt_dlp
import uuid
import os

def download_and_process_video(url: str) -> str:
    """
    Downloads video from a URL.
    Tries to find a pre-merged MP4 to avoid requiring FFmpeg for merging.
    """
    filename = f"/tmp/{uuid.uuid4()}.mp4"
    
    # Ensure the temp directory exists
    os.makedirs("/tmp", exist_ok=True)
    
    ydl_opts = {
        #prefer mp4, but take anything best if mp4 fails
        'format': 'best[ext=mp4]/best',
        'outtmpl': filename,
        'noplaylist': True,
        'quiet': True,
        'overwrites': True,
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
        return filename
    except Exception as e:
        if os.path.exists(filename):
            os.remove(filename)
        raise RuntimeError(f"Video download failed: {str(e)}")

async def analyze_text_logic(text_content: str):
    """
    Analyzes raw text for AI generation patterns.
    """
    # cache check
    text_id = hashlib.md5(text_content.encode()).hexdigest()
    
    if cached := cache.get(text_id):
        print(f"‚ö° Text Cache HIT")
        return json.loads(cached)

    print(f"üê¢ Text Cache MISS. Analyzing...")

    try:
        # gemini analysis
        prompt = """
        You are an AI-Detector. Analyze this text to determine if it was generated by an AI/LLM.
        Look for: overly formal tone, lack of personal anecdote, repetitive sentence structure, and 'hallucination' patterns.

        Return JSON ONLY:
        {
            "Detector_score": int (0-100, where 100 is definitely AI),
            "verdict": "Human" | "AI-Generated" | "Mixed",
            "content_analysis": {
                "writing_style": "Formal/Casual/Robotic",
                "indicators": ["list of specific phrases or patterns found"]
            }
        }
        """

        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=[prompt, text_content]
        )
        
        # Clean JSON
        raw_text = response.text.replace("```json", "").replace("```", "").strip()
        result = json.loads(raw_text)

        # 3. Cache Result
        cache.setex(text_id, 86400, json.dumps(result))
        return result

    except Exception as e:
        print(f"‚ùå Text Error: {e}")
        return {
            "Detector_score": 0, "verdict": "Error",
            "content_analysis": {"error": str(e)}
        }