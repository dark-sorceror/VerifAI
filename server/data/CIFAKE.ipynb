{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f8683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kaggle' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv kaggle\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"KAGGLE_USERNAME\") or not os.getenv(\"KAGGLE_KEY\"):\n",
    "    print(\"Error: Kaggle credentials not found in .env file.\")\n",
    "else:\n",
    "    print(\"Credentials loaded successfully.\")\n",
    "\n",
    "!kaggle datasets download -d birdy654/cifake-real-and-ai-generated-synthetic-images\n",
    "\n",
    "print(\"Downloading and unzipping dataset...\")\n",
    "\n",
    "!unzip -q cifake-real-and-ai-generated-synthetic-images.zip\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add2a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('train') and os.path.exists('test'):\n",
    "    print(f\"Real Images Dataset: {len(os.listdir('train/REAL'))}\")\n",
    "    print(f\"Fake Images Dataset: {len(os.listdir('train/FAKE'))}\")\n",
    "else:\n",
    "    print(\"Error, datasets not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20946b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Training Data ---\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '.\\\\train\\\\REAL'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.array(features), np.array(labels)\n\u001b[32m     71\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Loading Training Data ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m X_train, y_train = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Loading Test Data ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m X_test, y_test = load_dataset(\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(root_dir, subset_name)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label_name, label_idx \u001b[38;5;129;01min\u001b[39;00m classes.items():\n\u001b[32m     53\u001b[39m     folder_path = os.path.join(base_path, label_name)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     image_files = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m MAX_IMAGES:\n\u001b[32m     57\u001b[39m         image_files = image_files[:MAX_IMAGES]\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: '.\\\\train\\\\REAL'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "MAX_IMAGES = 2000 \n",
    "IMG_SIZE = 128\n",
    "\n",
    "MODEL_PATH = Path(\"../model/\")\n",
    "\n",
    "def get_azimuthal_average(magnitude_spectrum):\n",
    "    h, w = magnitude_spectrum.shape\n",
    "    center = (h // 2, w // 2)\n",
    "    y, x = np.indices((h, w))\n",
    "    \n",
    "    r = np.sqrt((x - center[0])**2 + (y - center[1])**2).astype(int)\n",
    "    \n",
    "    tbin = np.bincount(r.ravel(), weights=magnitude_spectrum.ravel())\n",
    "    nr = np.bincount(r.ravel())\n",
    "    \n",
    "    radial_profile = tbin / np.maximum(nr, 1)\n",
    "    \n",
    "    return radial_profile[:60] \n",
    "\n",
    "def extract_features(img_path):\n",
    "    try:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None: return None\n",
    "        \n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        \n",
    "        f = np.fft.fft2(img)\n",
    "        fshift = np.fft.fftshift(f)\n",
    "        magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-9)\n",
    "        \n",
    "        return get_azimuthal_average(magnitude_spectrum)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def load_dataset(root_dir, subset_name):\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    classes = {'REAL': 0, 'FAKE': 1}\n",
    "    \n",
    "    base_path = os.path.join(root_dir, subset_name)\n",
    "    \n",
    "    for label_name, label_idx in classes.items():\n",
    "        folder_path = os.path.join(base_path, label_name)\n",
    "        image_files = os.listdir(folder_path)\n",
    "        \n",
    "        if MAX_IMAGES:\n",
    "            image_files = image_files[:MAX_IMAGES]\n",
    "            \n",
    "        print(f\"Processing {len(image_files)} images from {subset_name}/{label_name}...\")\n",
    "        \n",
    "        for fname in tqdm(image_files):\n",
    "            path = os.path.join(folder_path, fname)\n",
    "            data = extract_features(path)\n",
    "            \n",
    "            if data is not None:\n",
    "                features.append(data)\n",
    "                labels.append(label_idx)\n",
    "                \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "print(\"Loading Training Data...\")\n",
    "\n",
    "X_train, y_train = load_dataset('.', 'train')\n",
    "\n",
    "print(\"\\nLoading Test Data...\")\n",
    "\n",
    "X_test, y_test = load_dataset('.', 'test')\n",
    "\n",
    "print(\"\\nTraining SVM Classifier...\")\n",
    "\n",
    "model = SVC(kernel='rbf', probability=True) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nEvaluating Model...\")\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {acc * 100:.2f}%\")\n",
    "print(classification_report(y_test, predictions, target_names=['REAL', 'FAKE']))\n",
    "\n",
    "print(\"\\nSaving Model...\")\n",
    "\n",
    "joblib.dump(model, f\"{MODEL_PATH}/deepfake_detector.pkl\")\n",
    "\n",
    "print(f\"Saved: {MODEL_PATH}/deepfake_detector.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
